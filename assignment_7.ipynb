{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "1.A data pipeline is a sequence of data preprocessing and modeling steps that are combined to create a single process. It simplifies the workflow by automating the various stages of machine learning, from preprocessing the data to making predictions. Core elements of the machine learning process can be refined or automated once mapped within a machine learning pipeline¹. \n",
    "\n",
    "2.Data pipelines are responsible for collecting, processing, and storing data that will be used to train and test models. To make sure that your machine learning project has a successful outcome, you need to make sure your pipeline is well maintained throughout the entire process – from start to finish². \n",
    "\n",
    "3.Data pipelines capture and deliver the information that’s being used in a machine learning model. It’s how a team determines what data they want to process, what needs to happen, and where it needs to go next². \n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
