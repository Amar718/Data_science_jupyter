{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "1. Feature extraction is the process of automatically identifying and extracting relevant features from raw input data (such as images) that can be used as inputs to machine learning models (such as CNNs). In the context of CNNs, feature extraction is typically performed by applying a series of convolutional filters to the input image, which extract increasingly complex features at different spatial scales. These features are then passed through one or more fully connected layers to produce a final output.\n",
    "\n",
    "2. Backpropagation is an algorithm used to train neural networks (including CNNs) by iteratively adjusting the weights of the network based on the error between its predicted outputs and the true outputs. In the context of computer vision tasks, backpropagation is typically used to optimize the weights of a CNN so that it can accurately classify or detect objects in images.\n",
    "\n",
    "3. Transfer learning is a technique in which a pre-trained neural network (such as a CNN) is used as a starting point for training a new model on a different but related task. The idea behind transfer learning is that the pre-trained model has already learned useful features from a large dataset, which can be fine-tuned for the new task with a smaller dataset. This can lead to faster training times and better performance than training a new model from scratch.\n",
    "\n",
    "4. Data augmentation is a technique used to artificially increase the size of a training dataset by applying various transformations (such as rotations, translations, and flips) to the original images. This can help prevent overfitting and improve model generalization. Different techniques for data augmentation can have different impacts on model performance depending on the specific task and dataset.\n",
    "\n",
    "5. CNNs approach object detection by dividing an input image into a grid of smaller regions and applying convolutional filters at each region to extract features. These features are then passed through one or more fully connected layers to produce a final output that predicts the presence and location of objects in the image. Popular architectures for object detection include YOLO (You Only Look Once), Faster R-CNN (Region-based Convolutional Neural Network), and SSD (Single Shot Detector).\n",
    "\n",
    "6. Object tracking is the process of following an object over time in a video sequence. In CNNs, object tracking can be implemented by using an object detector (such as YOLO or Faster R-CNN) to detect objects in each frame of the video and then associating these detections across frames based on their spatial and temporal proximity.\n",
    "\n",
    "7. Object segmentation is the process of dividing an input image into regions that correspond to different objects or parts of objects. In CNNs, object segmentation can be accomplished by using convolutional filters to extract features at different spatial scales and then applying these features to generate pixel-wise predictions for each region.\n",
    "\n",
    "8. CNNs can be applied to optical character recognition (OCR) tasks by treating each character in an image as an object and using an object detector (such as YOLO or Faster R-CNN) to detect and classify each character separately.\n",
    "\n",
    "9. Image embedding is a technique used to represent images as high-dimensional vectors that capture their semantic content. Image embeddings can be used for various computer vision tasks such as image retrieval, clustering, and classification.\n",
    "\n",
    "10. Model distillation is a technique used to transfer knowledge from a large, complex neural network (such as a CNN with many layers) to a smaller, simpler network with fewer layers and parameters. This can improve model performance and efficiency by reducing overfitting and computational complexity.\n",
    "\n",
    "11. Model quantization is a technique used to reduce the memory footprint of neural network models by representing their weights and activations using fewer bits than their full precision counterparts.\n",
    "\n",
    "12. Distributed training is an approach in which multiple devices (such as GPUs or CPUs) are used in parallel to train a neural network model on large datasets. This can lead to faster training times and better scalability than training on a single device.\n",
    "\n",
    "13. PyTorch and TensorFlow are two popular frameworks for developing neural network models (including CNNs). PyTorch is known for its ease-of-use and dynamic computational graph construction, while TensorFlow is known for its scalability and support for distributed training.\n",
    "\n",
    "14. GPUs are commonly used for accelerating CNN training and inference due to their ability to perform large-scale parallel computations efficiently.\n",
    "\n",
    "15. Occlusion and illumination changes can affect CNN"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
