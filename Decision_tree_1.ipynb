{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "Q1. A decision tree classifier is a supervised machine learning algorithm that uses a set of rules to make decisions, similarly to how humans make decisions¹. It builds a flowchart-like tree structure where each internal node denotes a test on an attribute, each branch represents an outcome of the test, and each leaf node holds a class label⁴. To make a prediction, the algorithm starts from the root node and follows the branches according to the values of the attributes until it reaches a leaf node².\n",
    "\n",
    "Q2. The mathematical intuition behind decision tree classification is based on the concept of information gain. Information gain measures how much information a feature provides about the class. The algorithm tries to maximize the information gain at each split by choosing the feature that best separates the data into different classes³. The information gain can be calculated using different criteria, such as Gini impurity, entropy, or log loss⁵.\n",
    "\n",
    "Q3. A decision tree classifier can be used to solve a binary classification problem by assigning one of two possible classes to each leaf node. For example, if we want to classify whether a person has diabetes or not based on their age, blood pressure, and glucose level, we can build a decision tree that splits the data according to these features and assigns either \"diabetes\" or \"no diabetes\" to each leaf node².\n",
    "\n",
    "Q4. The geometric intuition behind decision tree classification is that it partitions the feature space into rectangular regions that correspond to different classes. Each region is defined by the boundaries of the splits made by the algorithm along the axes of the features. For example, if we have two features x and y, and we split the data at x = 5 and y = 10, we create four regions: (x < 5 and y < 10), (x < 5 and y > 10), (x > 5 and y < 10), and (x > 5 and y > 10). Each region will have a majority class that determines the prediction for any point in that region⁴.\n",
    "\n",
    "Q5. The confusion matrix is a table that shows how well a classification model performs on a set of test data. It compares the actual labels with the predicted labels and counts how many instances fall into four categories: true positives (TP), true negatives (TN), false positives (FP), and false negatives (FN). The confusion matrix can be used to evaluate the performance of a classification model by calculating various metrics, such as accuracy, precision, recall, and F1 score².\n",
    "\n",
    "Q6. An example of a confusion matrix is:\n",
    "\n",
    "|              | Predicted Positive | Predicted Negative |\n",
    "|--------------|--------------------|--------------------|\n",
    "| Actual Positive | TP = 50             | FN = 10             |\n",
    "| Actual Negative | FP = 20             | TN = 70             |\n",
    "\n",
    "From this confusion matrix, we can calculate:\n",
    "\n",
    "- Precision = TP / (TP + FP) = 50 / (50 + 20) = 0.71\n",
    "- Recall = TP / (TP + FN) = 50 / (50 + 10) = 0.83\n",
    "- F1 score = 2 * Precision * Recall / (Precision + Recall) = 2 * 0.71 * 0.83 / (0.71 + 0.83) = 0.77\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
