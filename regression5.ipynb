{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "Elastic Net Regression is a **regularized regression method** that combines the **L1 and L2 penalties** of the lasso and ridge methods to deal with **multicollinearity** and **overfitting** issues²¹. It can also perform **variable selection** by shrinking some coefficients to zero³.\n",
    "\n",
    "There are many aspects to Elastic Net Regression, such as how to choose the optimal values of the regularization parameters, how to interpret the coefficients, how to handle missing values, how to use it for feature selection, and how to pickle and unpickle a trained model in Python.\n",
    "\n",
    "The **L1 penalty** is computed as the **sum of the absolute values** of the coefficients²⁴. It tends to **shrink some coefficients to zero** and perform variable selection³⁴. The L1 penalty is also known as the **Laplace prior**⁶.\n",
    "\n",
    "The **L2 penalty** is computed as the **sum of the squares** of the coefficients²⁴. It tends to **shrink all coefficients by the same factor** and prevent overfitting³⁴. The L2 penalty is also known as the **Gaussian prior**⁶.\n",
    "\n",
    "Elastic Net Regression combines both L1 and L2 penalties to achieve a balance between variable selection and regularization¹.\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
