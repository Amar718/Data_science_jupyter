{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "Q1. The Filter method is a feature selection technique that uses statistical measures to score the correlation or dependence between input variables and the target variable. The features with the highest scores are selected for the model¹.\n",
    "\n",
    "Q2. The Wrapper method is a feature selection technique that uses a predictive model to evaluate the performance of different subsets of features and select the best one¹. The Wrapper method differs from the Filter method in that it considers the interaction between features and the model, but it is more computationally expensive².\n",
    "\n",
    "Q3. Some common techniques used in Embedded feature selection methods are Lasso regression, Ridge regression, Elastic Net, Decision Tree, and Random Forest³. These methods incorporate feature selection as part of the model training process and select the optimal features based on the model's objective function¹.\n",
    "\n",
    "Q4. Some drawbacks of using the Filter method for feature selection are: it does not account for the interaction between features and the model, it may select redundant or irrelevant features, it may be biased by the choice of statistical measure, and it may not generalize well to unseen data¹².\n",
    "\n",
    "Q5. You would prefer using the Filter method over the Wrapper method for feature selection in situations where: you have a large number of features, you want a fast and simple technique, you do not have a specific model in mind, or you want to avoid overfitting¹².\n",
    "\n",
    "Q6. To choose the most pertinent attributes for the customer churn model using the Filter method, you could follow these steps: 1) Identify the target variable (e.g., churn or not churn). 2) Select a statistical measure to score the features (e.g., chi-square, information gain, correlation coefficient). 3) Apply the measure to each feature and rank them according to their scores. 4) Choose a threshold or a number of features to select based on your criteria (e.g., significance level, performance improvement). 5) Retain only the selected features for the model¹².\n",
    "\n",
    "Q7. To use the Embedded method to select the most relevant features for the soccer match predictor, you could follow these steps: 1) Choose a model that has an embedded feature selection mechanism (e.g., Decision Tree, Random Forest). 2) Train the model on the dataset with all the features. 3) Extract the feature importance scores from the model (e.g., Gini index, entropy reduction). 4) Rank the features according to their scores and select the top ones based on your criteria (e.g., performance improvement, complexity reduction). 5) Use only the selected features for the final model¹³.\n",
    "\n",
    "Q8. To use the Wrapper method to select the best set of features for the house price predictor, you could follow these steps: 1) Choose a model that you want to use for prediction (e.g., Linear Regression, KNN). 2) Define a performance metric to evaluate the model (e.g., R-squared, MSE). 3) Apply a search algorithm to explore different subsets of features (e.g., forward selection, backward elimination, genetic algorithm). 4) For each subset of features, train and test the model on a validation set and record its performance. 5) Select the subset of features that gives the best performance on the validation set¹².\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
